\section*{ГЛАВА 3}
\section*{ПРОЕКТИРОВАНИЕ ПРОГРАММНОГО СРЕДСТВА}
\addcontentsline{toc}{section}{ГЛАВА 3}
\addcontentsline{toc}{section}{ПРОЕКТИРОВАНИЕ ПРОГРАММНОГО СРЕДСТВА}
\setcounter{section}{3}
\setcounter{subsection}{0}
\bigskip

Исходя из требований и современных стандартов разработки, программное средство должно обладать следующими свойствами:
\begin{itemize}
    \item модульность;
    \item простота сопровождения;
    \item параллельная обработка данных;
    \item безопасность хранения конфиденциальных и личных данных.
\end{itemize}

Для соответствия выше описанным свойствам было принято решение разрабатывать программное средство с использованием монолитной архитектуры. Так как использование микросервисной архитектуры упростило бы горизонтальное масштабирование и уменьшило бы связность модулей, однако данный подход требует дополнительный усилий по развертыванию, мониторингу и поддерживанию работоспособности программного средства что делает его использование нецелесообразным. 

Разработанное программное средство состоит из следующих модулей:
\begin{itemize}
    \item модуль выделения признаков почерка;
    \item модуль определения характеристик личности;
    \item модуль биометрической аутентификации;
    \item модуль определения неврологических отклонений;
    \item модуль контроля доступа;
    \item модуль доступа к базе данных.
\end{itemize}

Вышеописанные модули опираются на следующие группы классов, разработанные в рамках диссертационной работы:
\begin{itemize}
    \item набор классов для сегментации образца на строки, слова, символы и выделения признаков. Написан на языке Scala;
    \item набор классов машинного обучения (для классификации признаков текста). Написан на языке программирования Scala и содержит реализацию алгоритма основанного на методе опорных векторов (Support Vector Machine), подробнее рассмотрен в главе~\ref{sec:architecture:personal_parameters};
    \item набор классов для контроля доступа. Написана на языке Scala. Содержит классы для регистрации, авторизации и управлением сессией пользователя. Основан на стандарте JSON Web Token (JWT);
    \item набор классов для организации доступа и хранения авторизационных данным пользователя и коллекции обработанных образцов.
\end{itemize}

Далее приведено подробное описание структуры и назначения каждого модуля.
\subsection{Модуль определения неврологических отклонений}
\label{sec:architecture:neuro_ill}
Основываясь на анализе литературных источников в разделе~\ref{sub:domain:literary_sources} и спецификации требований (раздел~\ref{sec:freq:neuro_analysis}) было принято решение для определения неврологических отклонений по признаком рукописного текста использовать размер символов почерка и среднеквадратичное отклонение от скелета символа.

Так как в результирующем наборе параметров, описанный в разделе~\ref{sec:architecture:feature_extraction}, не присутствует размер символов напрямую и для улучшения качества анализа используется набор признаков состоящий из
следующий признаков:
\begin{itemize}
  \item площадь;
  \item интервал между символами;
  \item интервал между словами;
  \item интервал между строками;
  \item частота текста.
\end{itemize}

На основание вышеперечисленных признаков строится заключение об общем размере элементов рукописного текста.
Для проведения скелетизации используется метод уточнения областей. Стоит отметить что из-за формата хранения данных в виде трех отдельных массивов, как и в случае со сегментацией, необходимо преобразовать в единую матрицы координат точек.

При расчете среднеквадратичного отклонения учитываются три смежные точки исходного образца:   
\begin{equation}
  \label{eq:architecture:sko}
  S = \sqrt{\frac{1}{3 n} \sum\limits_{i=1}^{n}\sum\limits_{k=-1}^{1} d(q_i,a_{i+k})^2},
\end{equation}
\begin{explanation}
где & $ S $ & величина среднеквадратичного отклонения; \\
    & $ n $ & количество точек образца; \\
    & $ d(q,a) $ & евклидово расcтояние между точками $q$ и $a$; \\
    & $ q_i $ & точка скелета образца; \\
    & $ a_{i+k} $ & точка исходного образца.
\end{explanation}

На основании величины среднеквадратичного отклонения и интегральной метрики размера элементов почерка может быть рассчитанна вероятность наличия неврологических отклонений.

\subsection{Модуль биометрической аутентификации}
\label{sec:architecture:bioauth}
Основываясь на анализе литературных источников в разделе~\ref{sub:domain:literary_sources}, спецификации требований (раздел~\ref{sec:freq:bio_identification}) и факта что признаки почерка подчиняются нормальному распределению было принято решение использования радиально-базисную функцию Гаусса, представленную в главе~\ref{eq:architecture:gaussian_core} и описываемую формулой~(\ref{eq:architecture:gaussian_core}).

На этапе построения эталона используется 5 образцов почерка, ранее сохраненных в базу данных, на основе выделенных признаков которых и рассчитываются распределения для каждого из признаков.

На этапе аутентификация из представленного образца выделяются признаки почерка и проводится оценка сходства по формуле:

\begin{equation}
  \label{eq:architecture:major_bio_auth}
  R(S) = \frac{1}{n} \sum\limits_{i=1}^{n} w_i \cdot \exp(-\frac{\left|\left| s_i - x_i^{'} \right|\right|}{2\sigma_{i}^2}),
\end{equation}
\begin{explanation}
где & $ R(S) $ & величина сходства образцов;\\
    & $ n $ & количество сравниваемых празнаков почерка;\\
    & $ w_i $ & вес $i$-го признака почерка (коэффициент от 0 до 1);\\
    & $ s_i $ & значение $i$-го признака почерка предъявляемого образца;\\
    & $ x_i^{'}$ & среднее значение $i$-го признака почерка эталонных образцов;\\
    & $ \sigma_{i} $ & дисперсия значения $i$-го признака почерка эталонных образцов. 
\end{explanation}

Далее полученное значение $R(S)$ сравнивается с пороговым значением аутентификации, например 0.85, и выносится решение об успешности процедуры аутентификации.

\subsection{Модуль определения характеристик личности}
\label{sec:architecture:personal_parameters}
Основываясь на анализе литературных источников в разделе~\ref{sub:domain:literary_sources} и спецификации требований, раздел~\ref{sec:freq:psiho_analysis}, было принято решение для определения характеристик личности по признаком рукописного текста использовать классификатор на основе метода опорных векторов, широко используемого метода машинного обучения~\cite{manning_ir}, который при своей относительной простоте реализации, позволяет добиться очень неплохих результатов классификации.

Метод опорных векторов (\emph{SVM, support vector machine}) – семейство схожих алгоритмов обучения с учителем, использующихся для задач классификации и регрессионного анализа. Особым свойством метода опорных векторов является непрерывное уменьшение эмпирической ошибки классификации и увеличение зазора, поэтому метод также известен как метод классификатора с максимальным зазором~\cite{mitchell_ml, wiki_SVM}.

Параметры текста представляют собой непрерывные величины подчиняющиеся нормальному распределению (рисунок~\ref{fig:architecture:normal_pd}). Исходя их этого свойства использование полиномиальных однородных и неоднородных ядер не позволит достичь хороший результатов классификации, для достижения хороших результатов распознавания следует использовать в качестве ядер радиально-базисная функцию Гаусса~\cite{wiki_gauss, orr}:

\begin{equation}
  \label{eq:architecture:gaussian_core}
  k(x) = \exp(-\frac{\left|\left| x - x^{'} \right|\right|}{2\sigma_{}^2}),
\end{equation}
\begin{explanation}
где & $x^{'}$ & среднее значение параметра, рассчитанное для объектов, принадлежащих
классу $C$; \\
    & $ \sigma_{}^2 $ & дисперсия значения параметра объектов из класс $C$.
\end{explanation}

Дисперсия значения параметра представлена формулой:
\begin{equation}
  \label{eq:architecture:dispersion}
  \sigma_{}^2 = \frac{1}{n - 1} \sum\limits_{x \in C} (x_i - \overline{x_{}}^2).
\end{equation}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/gauss.png}
    \caption{График функции плотности вероятности для нормального распределения}
    \label{fig:architecture:normal_pd}
\end{figure}

\subsection{Модуль выделения признаков почерка}
\label{sec:architecture:feature_extraction}
На основании требование, сформированных в разделе~\ref{sec:freq:extract_features}, основным функциями данного модуля являются:
\begin{itemize}
  \item подготовка образца к обработке;
  \item сегментация образца;
  \item выделения признаков почерка.
\end{itemize}

Учитывая цифровой формат ввода образца, процесс подготовки сводится к построению единой матрицы координат точек из двух массивов координат точек и массива флагов разрыва.

Следующий этапам является сегментация образца, а первой стадией сегментации является сегментация строк.
Задача выделения строк сводиться к нахождению верхних и нижних граней строк текста на исходном образце. Алгоритм сегментации строк основывается на том, что средняя плотность точек в межстрочных промежутках существенно ниже средней плотности точек в текстовых строк~\cite{cv_text_image_segmentator}.

Первым этапом необходимо для всех строк образца находим их значения плотности точек:
\begin{equation}
  \label{eq:architecture:line_medium_brigth}
  d_j = d_j(M) = \frac{1}{n}\cdot\sum\limits_{i=1}^{n} m_{ij}.
\end{equation}

Затем необходимо определить среднюю плотность точек всего образца:
\begin{equation}
  \label{eq:architecture:medium_brigth}
  d(M) = \frac{1}{l}\cdot\sum\limits_{j=1}^{l} d_j(M).
\end{equation}

Средняя плотность точек в межстрочных интервалах невелика (близка к нулю). Поэтому плотность точек верхней границы строки можно выразить из плотности точек всего образца:
\begin{equation}
  \label{eq:architecture:line_up_interval_medium_brigth}
  d^{t} = k_{t} \cdot d(M),
\end{equation}
\begin{explanation}
где & $ k_{t} $ & коэффициент от 0 до 1.
\end{explanation}

Аналогично плотность нижней границы может быть выражена через плотности точек всего образца:
\begin{equation}
  \label{eq:architecture:line_down_interval_medium_brigth}
  d^{b} = k_{b} \cdot d(B),
\end{equation}
\begin{explanation}
где & $ k_{b} $ & коэффициент от 0 до 1.
\end{explanation}

Работа алгоритма заключается в последовательном просмотре массива средних значений $ (d_1,...,d_m) $ и выявлении множества пар индексов $ (d^t_i,d^b_i) $ строк соответствующих ниже приведенным условиям и следовательно являющимися верхней $ d^t_i $ и нижней $ d^b_i $ границам строк.

Условия верхней границы текстовой строки:
\begin{itemize}
  \item плотность точек текущей строки превышает границу $ d^{t} $;
  \item плотность точек двух предыдущих строк ниже этой границы;
  \item плотность точек трех последующих строк выше границы $ d^{b} $.
\end{itemize}

Следовательно, должно выполняться логическое условие:
\begin{equation}
  \label{eq:architecture:logic_up_interval}
  (d_{i-2} < d^{t}) \wedge (d_{i-1} < d^{t}) \wedge (d_i > d^{b}) \wedge (d_{i+1} > d^{b}) \wedge (d_{i+2} > d^{b}) \wedge (d_{i+3} > d^{b}).
\end{equation}

Условия нижней границы текстовой строки:
\begin{itemize}     
  \item было зафиксировано начало области;
  \item плотность точек текущей строки превышает границу $ d^{t} $;
  \item плотность точек последующей строки ниже границы $ d^{b} $.
\end{itemize}
     
Или:

\begin{itemize}
   \item было зафиксировано начало области;
   \item плотность точек трех последующих строк ниже границы $ d^{b} $.
\end{itemize}

Следовательно, должно выполняться логическое условие:
\begin{equation}
  \label{eq:architecture:logic_down_interval}
  ((d_{i+1} < d^{b}) \wedge (d_{i+2} < d^{b}) \wedge (d_{i+3} < d^{b}) \vee ((d_i > d^{t}) \wedge (d_{i+1} < d^{b}))).
\end{equation}

Результатом работы алгоритма является множество пар индексов верхних и нижних границ строк. На основе этих данных можно рассчитать высоты строки (разность между индексами). Недостатком данного алгоритма является <<срезание>> символов, которые имеют высоту выше средней.

Для устранения этого недостатка можно использовать следующий прием расширения найденной границы. Необходимо определить строку с минимальной высотой $ H_{min} $, а затем границы всех строк на величину $ 0.3 \cdot  H_{min} $. Данный шаг не приведет к слиянию строк, т.к. межстрочные интервалы текста, как правило, больше чем высота строки.
 
Алгоритмы сегментации слов и символом сходи с алгоритмом сегментации строк. Основными отличиями являются необходимость построения карты плотности столбцов, а не строк, а так же наличие дополнительных этапов постобработки, направленных на удаление ложных границ после сегментации слов и символов. Исходными данными следующего алгоритма являются результаты работы предыдущего, так на вход алгоритма сегментации слов подается результат сегментации строк.

Для сегментации образцов можно использовать готовый алгоритм реализованный в сторонней системы распознавания рукописного текста, например Tesseract или ABBYY FineReader. Однако данный подход требует дополнительных усилий по предварительной обработке образца почерка и лишает разработчика возможности оптимизировать алгоритм под конкретную задачу. Помимо часть подобных средств распространяется на платной основе, что увеличит стоимость разработки и сопровождения.

Следующей функцией данного модуля является выделение из образца следующих признаков текста:
\begin{itemize}
  \item длительность написания;
  \item количество линий;
  \item длина по горизонтали;
  \item длина по вертикали;
  \item площадь;
  \item общая длина;
  \item максимальное ускорение;
  \item минимальное ускорение;
  \item длительность написание по вертикали;
  \item длительность написание по горизонтали;
  \item наклон символов;
  \item наклон строк;
  \item интервал между символами;
  \item интервал между словами;
  \item интервал между строками;
  \item частота текста.
\end{itemize}

Для определения угла наклона символа необходимо определить координаты верхней и нижней точек символа и используя арктангенс вычислить угол:

\begin{equation}
  \label{eq:architecture:symbol_angle}
  \Theta = \tan^{-1}{\frac{y_2 - y_1}{x_2 - x_1}},
\end{equation}
\begin{explanation}
где & $\Theta$ & угол наклона символа; \\
    & $ (x_1, y_1) $ & координаты нижней точеки символа; \\
    & $ (x_2, y_2) $ & координаты верхней точеки символа.
\end{explanation}    

На рисунке~\ref{fig:architecture:symbol_angle} приведены примеры символов с выделенными верхними и нижними точками, координаты $ (x_2, y_2) и (x_1, y_1) $ соответственно и условно обозначенным угол $ \Theta $. Представлены образцы трех типов наклона символов левосторонний, правосторонний и прямой.

Сегментация рукописного текста является нетривиальной задачей ввиду непостоянства таких параметров как пробелы между символами, в плодь до их отсутствия, словами и строками. Задача становится еще сложнее учитывая то, что данные признаки необходимо сохранить и использовать в дальнейшей работе.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.85\textwidth]{figures/char_angle.png}
    \caption{Пример расчета угла наклона символа}
    \label{fig:architecture:symbol_angle}
\end{figure}

Поскольку процесс сегментации образцов и выделение признаков являются относительно долгими операциями, сегментация вместе с выделением признаков занимает от 0.5 до 3 секунды, в зависимости от особенностей образца, обеспечение параллельной обработки выходит на передний план. К счастью выбранные признаки почерка независимы и могут рассчитываться параллельно. Так же нет необходимость ожидать полной сегментации сегментации для начала выделения признаков, например интервал между строками можно вычислить сразу после разбиения образца на строки. Это позволит значительно ускорить работу данного модуля.

\subsection{Модуль доступа к данным}
Данный модуль отвечает за организацию работы с базой данных и предоставление другим модулям удобного интерфейса.
На основании требований, сформированных в разделах~\ref{sec:freq:show},~\ref{sec:freq:delete},~\ref{sec:freq:add}, основными функциями данного модуля являются:
\begin{itemize}
  \item добавление авторизационных данных пользователя в базу при регистрации (включая проверку дублирования имен пользователей);
  \item проверка наличия пользователя в базе и соответствие хеша пароля;
  \item добавление нового образца в базу;
  \item обновление информации о параметрах образца;
  \item удаление образца из базы.
\end{itemize}

Так как список параметров образца постоянный и значения параметров обновляются крайне редко, в данном случае рационально использование классической реляционной базы данных, не смотря на параллельное добавление параметров на этапе выделения, в тоже время на базу данных не налагается каких-либо существенных ограничений по быстродействию и скорости обработки запросов. Основываясь на выше перечисленном в качестве СУБД была выбрана PosgreSQL, описанный в главе~\ref{sec:techs:postgresql}.
Так же плюсом этого решения можно отнести возможность хранение в базе JSON-объектов, что исключает дополнительное преобразование данных перед отправкой их другим модулям и на клиент, а так же отсутствие платы за использование, что позволит снизить стоимость разработки и эксплуатации.

\subsection{Модуль контроля доступа}
Поскольку разрабатываемое приложение может содержать персональные данные пользователя, вплоть до имени и фамилии в графе комментариев к образцу, задача организации безопасного доступа и хранению подобных данных стоит довольно остро.

Данный модуль отвечает за регистрацию и авторизацию пользователей. 
В данной работе для предоставления защищенного доступа к модулям будет использоваться открытый стандарт JSON Web Token (RFC 7519). JWT-маркер  содержит в зашифрованном виде всю минимально необходимую информацию для аутентификации и авторизации. При этом не требуется хранить в сессии данных о пользователе, так как маркер самодостаточный. Данный факт упрощает организацию системы сессий и хорошо подход для выбранной архитектуры.

На рисунке~\ref{fig:architecture:jwt_diagram} представлен алгоритм создания, подписи и проверки JWT-маркера. В данном примере выдачу и проверку маркера осуществляет один и тот же сервер, однако, как было описано выше, это не является обязательным условием и представлено лишь для упрощения диаграммы.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.7\textwidth]{figures/jwt_diagram.png}
    \caption{Диаграмма генерации и верификации JWT-маркеров}
    \label{fig:architecture:jwt_diagram}
\end{figure}

На основании требований, сформированных в разделах~\ref{sec:freq:reg} и~\ref{sec:freq:auth}, основными функциями данного модуля являются:
\begin{itemize}
  \item регистрации новых пользователей;
  \item авторизация пользователей;
  \item генерация JWT"=маркеров.
\end{itemize}

Использование контроля доступа на основе JWT-маркеров позволяет снизить нагрузку на модуль контроля доступа, благодаря возможности проверки подлинности маркера на стороне других модулей.

\subsection{Краткие выводы}
В данном разделе была описана архитектура программного средства. Составлен список модулей и определены их взаимосвязи.  Выявлен исчерпывающий набор признаков почерка необходимый для проведения всех заявленных типов анализа.

Разработанное программное средство состоит из следующих модулей:
\begin{itemize}
    \item модуль биометрической аутентификации;
    \item модуль определения неврологических отклонений;
    \item модуль выделения признаков почерка;
    \item модуль определения характеристик личности;
    \item модуль доступа к базе данных.
    \item модуль контроля доступа;
\end{itemize}

Основываясь на вышеизложенном можно приступать к реализации программного средства.